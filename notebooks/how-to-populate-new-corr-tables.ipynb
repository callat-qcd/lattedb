{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This notebook displays how to create and query correlator data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union, List\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "import datetime\n",
    "import pytz\n",
    "\n",
    "from django.db import IntegrityError\n",
    "\n",
    "from lattedb.project.formfac.models.data.correlator import (\n",
    "    CorrelatorMeta,\n",
    "    DiskCorrelatorH5Dset,\n",
    "    TapeCorrelatorH5Dset,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a timezone for creating timezone aware objects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a time for the given timezone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_timezones = sorted([timezone for timezone in pytz.all_timezones if \"US\" in timezone])\n",
    "print([timezone.split(\"/\")[-1] for timezone in us_timezones])\n",
    "\n",
    "timezone = pytz.timezone(\"US/Michigan\")\n",
    "\n",
    "time = datetime.datetime(2020, 3, 11, 23, 59, 59, 1234, timezone)\n",
    "time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to create a Disk or Tape entry for correlators"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create a meta object (this is the object which will eventually replaced by the actual meta tables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_infos = {\"corr\": \"phi_qq\", \"configuration\": 200, \"source\": \"x22y21z20t19\"}\n",
    "corr_meta, created = CorrelatorMeta.objects.get_or_create(**meta_infos)\n",
    "corr_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next create a disk or Disk entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disk_infos = {\n",
    "    \"name\": \"corr.h5\",\n",
    "    \"path\": \"/summit/path/to/file/\",\n",
    "    \"dset\": \"phi_qq/cfg_199/src_x22y21z20t19/array\",\n",
    "    \"exists\": True,\n",
    "    \"machine\": \"Summit\",\n",
    "    \"date_modified\": time,\n",
    "    \"meta\": corr_meta,\n",
    "}\n",
    "disk_meta, created = DiskCorrelatorH5Dset.objects.get_or_create(**disk_infos)\n",
    "disk_meta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tape creation works the same way with the difference that you should use `TapeCorrelatorH5Dset` instead of `DiskCorrelatorH5Dset`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bulk push disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_list = []\n",
    "meta_tmp = meta_infos.copy()\n",
    "\n",
    "for cfg in range(21, 30):\n",
    "    meta_tmp[\"configuration\"] = cfg\n",
    "    # Create python object but do not push to db\n",
    "    meta_list.append(CorrelatorMeta(**meta_tmp))\n",
    "\n",
    "# Push to db\n",
    "## Note: This only works if objects do not exist\n",
    "try:\n",
    "    meta_objs = CorrelatorMeta.objects.bulk_create(meta_list)\n",
    "    print(meta_objs)\n",
    "except IntegrityError:\n",
    "    meta_objs = []\n",
    "    print(\"At least one object already exists in db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "disk_list = []\n",
    "disk_tmp = disk_infos.copy()\n",
    "\n",
    "for meta in meta_objs:\n",
    "    disk_tmp[\"dset\"] = f\"phi_qq/cfg_{meta.configuration}/src_x22y21z20t19/array\"\n",
    "    # Pass *existing* python meta object to file info\n",
    "    disk_tmp[\"meta\"] = meta\n",
    "    # Create python file object but do not push to db\n",
    "    disk_list.append(DiskCorrelatorH5Dset(**disk_tmp))\n",
    "\n",
    "\n",
    "# Push to db\n",
    "## Note: This only works if objects do not exist\n",
    "try:\n",
    "    disk_objs = DiskCorrelatorH5Dset.objects.bulk_create(disk_list)\n",
    "    print(disk_objs)\n",
    "except IntegrityError:\n",
    "    disk_objs = []\n",
    "    print(\"At least one object already exists in db\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find out if file exists somewhere for given meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_location(\n",
    "    corr: str, configuration: int, source: str\n",
    ") -> Union[DiskCorrelatorH5Dset, TapeCorrelatorH5Dset, None]:\n",
    "    \"\"\"Looks up if a given correlator can be found on disk or tape.\n",
    "    \n",
    "    Returns the corresponding object if found, else None.\n",
    "    If both disk and tape object exists, return Disk object first.\n",
    "    \"\"\"\n",
    "    obj = None\n",
    "    meta = CorrelatorMeta.objects.filter(\n",
    "        corr=corr, configuration=configuration, source=source\n",
    "    ).first()\n",
    "\n",
    "    if meta is not None:\n",
    "        if hasattr(corr_meta, \"disk\") and corr_meta.disk.exists:\n",
    "            obj = meta.disk\n",
    "        elif hasattr(corr_meta, \"tape\") and corr_meta.tape.exists:\n",
    "            obj = meta.tape\n",
    "\n",
    "    return obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_obj = get_file_location(**meta_infos)\n",
    "print(file_obj.type)\n",
    "print(file_obj.machine)\n",
    "print(file_obj.file_address)\n",
    "print(file_obj.dset)\n",
    "print()\n",
    "\n",
    "file_obj = get_file_location(\"mres\", 200, \"bla\")\n",
    "print(file_obj)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-check script logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Starting point for script is\n",
    "\n",
    "Given values:\n",
    "* `corr`\n",
    "* `ensemble`\n",
    "* `stream`\n",
    "* `source_set` (this fixes list of `sources`)\n",
    "\n",
    "List values:\n",
    "* `configuration`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORR = \"phi_qq\"\n",
    "ENS = \"a09m134XL\"\n",
    "STREAM = \"a\"\n",
    "SRC_SET = \"1-8\"\n",
    "CFGS = list(range(0, 60, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function creates or gets and returns all meta entries related to the given parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_meta_entries(\n",
    "    corr: str,\n",
    "    configuration_range: List[int],\n",
    "    ensemble: str,\n",
    "    stream: str,\n",
    "    source_set: str,\n",
    ") -> List[CorrelatorMeta]:\n",
    "    \"\"\"Returns queryset of CorrelatorMeta entries for given input\n",
    "    \n",
    "    Creates entries in bulk if they do not exist.\n",
    "    \"\"\"\n",
    "    # Pull all relevant meta entries to local python script\n",
    "    meta_entries = CorrelatorMeta.objects.filter(\n",
    "        corr=corr,\n",
    "        configuration__in=configuration_range,\n",
    "        ensemble=ensemble,\n",
    "        stream=stream,\n",
    "        source_set=source_set,\n",
    "    )\n",
    "\n",
    "    kwargs = {\n",
    "        \"corr\": corr,\n",
    "        \"ensemble\": ensemble,\n",
    "        \"stream\": stream,\n",
    "        \"source_set\": source_set,\n",
    "    }\n",
    "    src_min, src_max = source_set.split(\"-\")\n",
    "    srcs = range(int(src_min), int(src_max))  # inclusive or exclusive?\n",
    "\n",
    "    # Check if all entries are present\n",
    "    entries_to_create = []\n",
    "    for src, cfg in product(srcs, configuration_range):\n",
    "        meta_data = kwargs.copy()\n",
    "        meta_data[\"source\"] = src\n",
    "        meta_data[\"configuration\"] = cfg\n",
    "\n",
    "        if not meta_entries.filter(**meta_data).first():\n",
    "            entries_to_create.append(CorrelatorMeta(**meta_data))\n",
    "\n",
    "    # Create entries if not present\n",
    "    if entries_to_create:\n",
    "        created_entries = CorrelatorMeta.objects.bulk_create(entries_to_create)\n",
    "        print(f\"Created {len(created_entries)} entries\")\n",
    "        meta_entries = CorrelatorMeta.objects.filter(\n",
    "            corr=corr,\n",
    "            configuration__in=configuration_range,\n",
    "            ensemble=ensemble,\n",
    "            stream=stream,\n",
    "            source_set=source_set,\n",
    "        )\n",
    "\n",
    "    # Return all entries\n",
    "    return meta_entries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### @walkloud: Please check the default kwarg logic for entries which do not exist!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below function creates or gets and returns all tape/disk entries for related meta entries. You should check if the attributes make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_tape_entries(\n",
    "    meta_entries: List[CorrelatorMeta],\n",
    ") -> List[TapeCorrelatorH5Dset]:\n",
    "    \"\"\"Returns queryset of TapeCorrelatorH5Dset entries for given CorrelatorMeta entries\n",
    "    \n",
    "    Creates entries in bulk with status does not exist if they do not exist in DB.\n",
    "    \"\"\"\n",
    "    file_entries = TapeCorrelatorH5Dset.objects.filter(meta__in=meta_entries)\n",
    "    \n",
    "    # Create entries if not present\n",
    "    kwargs = {\n",
    "        \"name\": \"corr-name.h5\",\n",
    "        \"path\": \"/abs/path/to/file/folder\",\n",
    "        \"machine\": \"summit\",\n",
    "        \"exists\": False,\n",
    "    }\n",
    "    \n",
    "    if file_entries.count() != meta_entries.count():\n",
    "        entries_to_create = []\n",
    "        for meta in meta_entries:\n",
    "            data = kwargs.copy()\n",
    "            data[\"dset\"] = f\"/path/to/dset/{meta.configuration}/{meta}\"\n",
    "            data[\"meta\"] = meta\n",
    "            data[\"date_modified\"] = time\n",
    "            entries_to_create.append(TapeCorrelatorH5Dset(**data))\n",
    "        \n",
    "        created_entries = TapeCorrelatorH5Dset.objects.bulk_create(entries_to_create)\n",
    "        print(f\"Created {len(created_entries)} entries\")\n",
    "        file_entries = TapeCorrelatorH5Dset.objects.filter(meta__in=meta_infos)\n",
    "    \n",
    "    return file_entries\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_or_create_disk_entries(\n",
    "    meta_entries: List[CorrelatorMeta],\n",
    ") -> List[DiskCorrelatorH5Dset]:\n",
    "    \"\"\"Returns queryset of DiskCorrelatorH5Dset entries for given CorrelatorMeta entries\n",
    "    \n",
    "    Creates entries in bulk with status does not exist if they do not exist in DB.\n",
    "    \"\"\"\n",
    "    file_entries = DiskCorrelatorH5Dset.objects.filter(meta__in=meta_entries)\n",
    "    \n",
    "    # Create entries if not present\n",
    "    kwargs = {\n",
    "        \"name\": \"corr-name.h5\",\n",
    "        \"path\": \"/abs/path/to/file/folder\",\n",
    "        \"machine\": \"summit\",\n",
    "        \"exists\": False,\n",
    "    }\n",
    "    \n",
    "    if not file_entries.count() == meta_entries.count():\n",
    "        entries_to_create = []\n",
    "        for meta in meta_entries:\n",
    "            data = kwargs.copy()\n",
    "            data[\"dset\"] = f\"/path/to/dset/{meta.configuration}/{meta}\"\n",
    "            data[\"meta\"] = meta\n",
    "            data[\"date_modified\"] = time\n",
    "            entries_to_create.append(DiskCorrelatorH5Dset(**data))\n",
    "        \n",
    "        created_entries = DiskCorrelatorH5Dset.objects.bulk_create(entries_to_create)\n",
    "        print(f\"Created {len(created_entries)} entries\")\n",
    "        file_entries = DiskCorrelatorH5Dset.objects.filter(meta__in=meta_infos)\n",
    "    \n",
    "    return file_entries\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How a script would look like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this in the beginning. This will make sure that the db has all entries present.\n",
    "For example, if expected entries for all input parameters are not in the DB, they will be created.\n",
    "The file status will be `exists=False`.\n",
    "You should adjust the `path`, `dset` and other attributes to make sense.\n",
    "Entries which are already present in the db will be pulled to the local system and you can work with them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "meta_entries = get_or_create_meta_entries(CORR, CFGS, ENS, STREAM, SRC_SET)\n",
    "tape_entries = get_or_create_tape_entries(meta_entries)\n",
    "disk_entries = get_or_create_disk_entries(meta_entries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for entry in meta_entries.filter(tape__exists=False, disk__exists=False):\n",
    "    # do logic\n",
    "    tape = entry.tape\n",
    "    \n",
    "    tape.exists = True\n",
    "    tape.save()\n",
    "    \n",
    "    disk = entry.disk\n",
    "    print(disk.file_address)\n",
    "    break\n",
    "    \n",
    "tape_entries.filter(exists=True).count()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lattedb",
   "language": "python",
   "name": "lattedb"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
